import numpy as np

'''
This file contains helper functions to calculate the metrics from the model:
1. Precision @ k
2. Recall @ k
3. Count correct prediction
4. Get K best prediction
'''

# Count valid?
# For each row, get the K-highest scoring label from the prediction
# K here refers to how many labels are being considered
# Then, check if the prediction is valid by checking whether the actual label is 1
# k: number of prediction that will be counted
# pred: the prediction result from the model
# return a 2D matrix where each row contain the top-k index for each prediction row
def get_k_best_prediction(k: int, pred):
    # sort the array
    index_list = []
    # Process each row using argpartition
    for row in pred:
        ind = np.argpartition(row, -k)[-k:]
        ind = ind[np.argsort(row[ind])][::-1]
        # Resulting index contain sorted from the highest to lowest of the k elements
        index_list.append(ind)
    return index_list

# Utilize the prediction index list calculated by get_k_best_prediction
# pred_index_list: return value of get_k_best prediction function
# labels: label array containing the correct labels
# Count the number of valid prediction (i.e., check whether the index
# in pred_index_list correspond to 1 value in the labels array)
def count_valid_prediction(pred_index_list, labels):
    # Check for each row
    count = 0
    for i in range(len(pred_index_list)):
        # Check for each item in the row (possibility of at most K items in the row)
        for item in pred_index_list[i]:
            if labels[i][item] == 1:
                count += 1
    return count



# Utilize the count correct prediction calculated by count_valid_prediction
# correct prediction: integer indicating the number of correct prediction
# labels: label array containing the correct labels
# THIS IS INCORRECT
# def get_recall(correct_prediction: int, labels):
#     # Count all the relevant entry (i.e., non-zero) from the labels
#     print("Correct prediction")
#     print(correct_prediction)
#
#     print("Labels")
#     print(labels)
#     count = np.count_nonzero(labels)
#     print("Total non zero: " + count.__str__())
#     return correct_prediction/count

def get_recall(prediction, labels):
    # Count all the relevant entry (i.e., non-zero) from the labels

    total_recall = 0
    for i in range(0, len(prediction)):
        correct_predict = 0
        # loop through the prediction
        for data in prediction[i]:
            if labels[i][data] == 1:
                correct_predict += 1
        total_recall += (correct_predict / np.count_nonzero(labels[i]))
    return total_recall / len(prediction)

def get_precision(correct_prediction: int, pred_index_list):
    # count the number of prediction
    temp = np.asarray(pred_index_list)
    array_shape = temp.shape
    num_prediction = array_shape[0] * array_shape[1]
    print("Precision:")
    print(correct_prediction)
    print(num_prediction)
    return correct_prediction/num_prediction

def get_f1(precision, recall):
    prec_rec = precision + recall
    if prec_rec == 0:
        return 0.0
    else:
        return 2 * (precision * recall) / prec_rec